{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MhxiaBRX-ku_"
      },
      "source": [
        "# Pre-Process Speech Dataset for *Efficient Speech* Model Training\n",
        "## Important: This notebook requires a GPU with CUDA available!\n",
        "\n",
        "  The notebook demonstrates preprocessing a speech dataset into the format expected by EfficientSpeech for training checkpoints.\n",
        "\n",
        "### **Dataset Specifications**\n",
        "#### Input Dataset format:\n",
        "This notebook assumes your dataset is a **folder** of Mono 22050Hz .wav files, with each audio file having a transcription text file with the same name.\n",
        "\n",
        "* `MyDataset`:  folder\n",
        "  - `speaker_001.wav`: an audio file\n",
        "  - `speaker_001.txt`: text transcription of speaker_001.wav\n",
        "  - ...\n",
        "  - `speaker_999.wav`\n",
        "  - `speaker_999.txt`\n",
        "\n",
        "#### Output Dataset format:\n",
        "The output for training is in this format:\n",
        "* `content/output_dataset`:  folder\n",
        "  - `configs/MyDataset`: folder\n",
        "    - `preprocess.yaml`: Only this file is necessary to train EfficientSpeech models\n",
        "    - `model.yaml`\n",
        "    - `train.yaml`\n",
        "  - `preprocessed_data/MyDataset`: folder\n",
        "    - `duration`: folder\n",
        "    - `energy`: folder\n",
        "    - `mel`: folder\n",
        "    - `pitch`: folder\n",
        "    - `TextGrid/universal`: folder of .TextGrid files\n",
        "    - `speakers.json`\n",
        "    - `stats.json`\n",
        "    - `train.txt`\n",
        "    - `val.txt`     \n",
        "  - `raw_data/universal`: folder\n",
        "    - `metadata.csv`: corpus file\n",
        "    - `speaker_001.wav`\n",
        "    - `speaker_001.txt`\n",
        "    - ...\n",
        "    - `speaker_999.wav`\n",
        "    - `speaker_999.txt`\n",
        "\n",
        "### Links\n",
        "EfficientSpeech repository: https://github.com/roatienza/efficientspeech  \n",
        "FastSpeech2 repository: https://github.com/ming024/FastSpeech2  \n",
        "Montreal Forced Aligner Tutorial: https://eleanorchodroff.com/mfa_tutorial.html"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcwbh_KvEXRJ"
      },
      "source": [
        "\n",
        "\n",
        "#  \n",
        "---\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aYacii8N55K9"
      },
      "source": [
        "## 0) Mount Google Drive\n",
        "If your dataset is in a folder named `MyDataset` in your Google Drive, the path would be `/gdrive/MyDrive/MyDataset`.  \n",
        "This step is optional if you upload your dataset some other way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYFbIeW2sv30",
        "outputId": "a9ef3d34-7269-4e42-c741-b12281c3e4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_dazMvsKE2WM"
      },
      "source": [
        "\n",
        "\n",
        "#  \n",
        "---\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "moJ46xEYJFt8"
      },
      "source": [
        "# 1) Run me first!\n",
        "## Install Conda and some prerequisites\n",
        "The runtime will restart after installation, please execute the remaining cells after the restart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8vSGcVLx7zt",
        "outputId": "9d2d23fa-ac58-4312-f7f2-eda57c8db6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.7-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Collecting pyworld==0.2.10\n",
            "  Downloading pyworld-0.2.10.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from pyworld==0.2.10) (0.29.34)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.2.10-cp310-cp310-linux_x86_64.whl size=885499 sha256=90e36618354981b0a8fc6a901df772bde421978854d2e0a7713cce468af1c138\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/6e/38/5c44182b8cdadd956e127d6b9dc2c4b539af20dfa43924f702\n",
            "Successfully built pyworld\n",
            "Installing collected packages: pyworld\n",
            "Successfully installed pyworld-0.2.10\n",
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:11\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install condacolab\n",
        "!pip install numpy==1.22.4 pyworld==0.2.10\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RrnL_21YEBWj"
      },
      "source": [
        "\n",
        "\n",
        "#  \n",
        "---\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "av3tMtIPtuyU"
      },
      "source": [
        "# 2) Prepare Dataset \n",
        "#### Make sure to configure the settings in the `Configuration Settings` section below before running these cells.\n",
        "Running these cells will preprocess your dataset and save it to your Drive as a .zip file.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob9m3Aiu44Nt"
      },
      "source": [
        "### Configuration Settings\n",
        "##### Dataset\n",
        "* dataset_name: The name of your dataset\n",
        "* dataset_path: A directory with the raw audio files + text transcriptions. The text and audio file names should match.\n",
        "* speaker_name: One of 'universal', 'LJSpeech'\n",
        "* val_size: The size of your validation set. (default: 512)  \n",
        "  - 0 < *val_size* < total audio files. \n",
        "  - Example: For FastSpeech2, LJSpeech config has 13,100 audio files with a *val_size* of 512.\n",
        "\n",
        "##### Output\n",
        "* output_path: Where to save the working files\n",
        "* output_zip_path: Where to save the finished dataset as a .zip file\n",
        "\n",
        "##### MFA (Montreal Forced Aligner) Settings\n",
        "* text_file_extension: the file format extension of the text transcription files.\n",
        "* corpus_name: 'metadata.csv'\n",
        "* lexicon_path: the lexicon/dictionary to use when running MFA.\n",
        "* dictionary_file: the lexicon/dictionary to use when preprocessing dataset  \n",
        "* allow_overwrite_existing_corpus: Enable to allow overwriting existing `corpus_name` file.\n",
        "* acoustic_model: MFA acoustic model (default: 'english_us_arpa')\n",
        "* dictionary_model - MFA dictionary model (unused)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yrU71RMluboT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# The input dataset\n",
        "dataset_name = 'MyDataset' #@param {type:'string'}\n",
        "dataset_path = '/gdrive/MyDrive/MyDataset' #@param {type:'string'}\n",
        "speaker_name = 'universal' #@param {type:'string'}\n",
        "val_size = 512 #@param {type:'integer'}\n",
        "\n",
        "# The output folder for processed data\n",
        "output_path = '/content/output_dataset' #@param {type:'string'}\n",
        "output_zip_path = '/gdrive/MyDrive/output_dataset'#@param {type:'string'}\n",
        "\n",
        "# MFA settings\n",
        "text_file_extension = '.lab' #@param ['.txt','.lab']\n",
        "corpus_name = 'metadata.csv' #@param {type:'string'}\n",
        "lexicon_path = '/content/FastSpeech2/lexicon/librispeech-lexicon.txt' #@param {type:'string'}\n",
        "dictionary_file = '/content/FastSpeech2/lexicon/librispeech-lexicon.txt' #@param {type:'string'}\n",
        "allow_overwrite_existing_corpus = True #@param {type:'boolean'}\n",
        "acoustic_model = 'english_us_arpa' #@param {type:'string'}\n",
        "dictionary_model = 'english_us_arpa' #@param {type:'string'}\n",
        "\n",
        "# Paths\n",
        "preprocessed_data_path = os.path.join(output_path, 'preprocessed_data')\n",
        "preprocessed_data_speaker_path = os.path.join(output_path, 'preprocessed_data',\n",
        "                                              dataset_name)\n",
        "raw_data_path = os.path.join(output_path, 'raw_data')\n",
        "raw_data_speaker_path = os.path.join(output_path, 'raw_data', speaker_name)\n",
        "corpus_path = raw_data_speaker_path\n",
        "corpus_file_path = os.path.join(corpus_path, corpus_name)\n",
        "mfa_output_path = os.path.join('/home/mfa_user', dataset_name, 'TextGrid')\n",
        "textgrid_dir = os.path.join(preprocessed_data_speaker_path, 'TextGrid', speaker_name)\n",
        "config_dir = f'/content/FastSpeech2/config/{dataset_name}'\n",
        "\n",
        "# Create directory structure\n",
        "%mkdir -p $output_path\n",
        "%mkdir -p $corpus_path\n",
        "%mkdir -p $preprocessed_data_speaker_path\n",
        "%mkdir -p $raw_data_speaker_path\n",
        "%mkdir -p $textgrid_dir\n",
        "%mkdir -p $output_zip_path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yat81N2Bt5KC"
      },
      "source": [
        "## Setup dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUca-LTTc4fi",
        "outputId": "1059ae7d-932f-4872-d38e-4b815c29946a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'FastSpeech2'...\n",
            "remote: Enumerating objects: 991, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 991 (delta 10), reused 7 (delta 7), pack-reused 978\u001b[K\n",
            "Receiving objects: 100% (991/991), 330.31 MiB | 30.69 MiB/s, done.\n",
            "Resolving deltas: 100% (175/175), done.\n",
            "Updating files: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "%rm -rf /content/FastSpeech2/\n",
        "%cd /content/\n",
        "!git clone https://github.com/ming024/FastSpeech2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pieRp9Uvx6az"
      },
      "source": [
        "### Install MFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO5ZAgRdyIDT",
        "outputId": "4e652f58-bc9a-4adf-de0d-c5cea992d4f5"
      },
      "outputs": [],
      "source": [
        "!conda install -c conda-forge montreal-forced-aligner"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OQbVwGsJL7cp"
      },
      "source": [
        "Create MFA user account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towszJaAL61o",
        "outputId": "5219f717-2182-4166-ca2b-55a65e13a0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "useradd: user 'mfa_user' already exists\n",
            "hello as mfa_user\n",
            "mkdir: cannot create directory ‚Äò/home/mfa_user‚Äô: File exists\n"
          ]
        }
      ],
      "source": [
        "# MFA commands must be run as unprivileged user\n",
        "!useradd -m -d /home/mfa_user mfa_user\n",
        "!su - mfa_user -c \"echo hello as mfa_user\"\n",
        "\n",
        "%mkdir /home/mfa_user\n",
        "!chown -hR mfa_user /home/mfa_user\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t1mpUQOWMkXh"
      },
      "source": [
        "Download MFA models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3juI4ATMzXVI",
        "outputId": "0fad30b3-b48e-4696-93cb-a50858a31b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.12\n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Saved model to                                                        \n",
            "\u001b[2;36m \u001b[0m         \u001b[35m/home/mfa_user/Documents/MFA/pretrained_models/acoustic/\u001b[0m\u001b[95menglish_us_arp\u001b[0m\n",
            "\u001b[2;36m \u001b[0m         \u001b[95ma.zip\u001b[0m, you can now use english_us_arpa in place of acoustic paths in  \n",
            "\u001b[2;36m \u001b[0m         mfa commands.                                                         \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Saved model to                                                        \n",
            "\u001b[2;36m \u001b[0m         \u001b[35m/home/mfa_user/Documents/MFA/pretrained_models/dictionary/\u001b[0m\u001b[95menglish_us_a\u001b[0m\n",
            "\u001b[2;36m \u001b[0m         \u001b[95mrpa.dict\u001b[0m, you can now use english_us_arpa in place of dictionary paths\n",
            "\u001b[2;36m \u001b[0m         in mfa commands.                                                      \n"
          ]
        }
      ],
      "source": [
        "# Excellent MFA tutorial: https://eleanorchodroff.com/mfa_tutorial.html\n",
        "!su - mfa_user -c \"mfa version\"\n",
        "!su - mfa_user -c \"mfa model download acoustic $acoustic_model\"\n",
        "!su - mfa_user -c \"mfa model download dictionary $dictionary_model\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ7P4NgEnXFj"
      },
      "source": [
        "### More dependencies required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qwtygw1aEGv",
        "outputId": "b8c8df28-5572-468f-a478-cf57b4f0940c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting librosa==0.9.2\n",
            "  Using cached librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "Collecting unidecode==1.3.6\n",
            "  Using cached Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "Collecting tgt==1.4.4\n",
            "  Using cached tgt-1.4.4.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyworld==0.2.10\n",
            "  Using cached pyworld-0.2.10-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (1.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (23.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (3.0.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (0.12.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (5.1.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (0.57.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/site-packages (from librosa==0.9.2) (1.10.1)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.10/site-packages (from pyworld==0.2.10) (0.29.35)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.2) (0.40.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.2) (3.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.2) (2.28.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.9.2) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (1.26.15)\n",
            "Building wheels for collected packages: tgt\n",
            "  Building wheel for tgt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tgt: filename=tgt-1.4.4-py3-none-any.whl size=28903 sha256=03797ca9fe3b3f41d1716f1f0b5756d50a2612c0aa84cf4ab2641d392e803e22\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e6/aa/821531faeb4e05a65d1c763570e90791467cf0c3f1622dc7e2\n",
            "Successfully built tgt\n",
            "Installing collected packages: tgt, unidecode, pyworld, resampy, librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0\n",
            "    Uninstalling librosa-0.10.0:\n",
            "      Successfully uninstalled librosa-0.10.0\n",
            "Successfully installed librosa-0.9.2 pyworld-0.2.10 resampy-0.4.2 tgt-1.4.4 unidecode-1.3.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Moving the order of dependencies around may cause errors. You have been warned! \n",
        "!pip install librosa==0.9.2 unidecode==1.3.6 tgt==1.4.4 pyworld==0.2.10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G_gn_upsCfgl"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "abIprDRxs3ic"
      },
      "source": [
        "#### YAML helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZGGmESwMcJEL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "\n",
        "# YAML functions\n",
        "def get_yaml_path(name):\n",
        "  return os.path.join(config_dir, name+'.yaml')\n",
        "\n",
        "\n",
        "def get_yaml_contents(name):\n",
        "  with open(get_yaml_path(name), 'r') as f:\n",
        "    return yaml.safe_load(f.read())\n",
        "            \n",
        "\n",
        "def write_yaml(name, contents):\n",
        "  with open(get_yaml_path(name), 'w') as f:\n",
        "    f.write(yaml.dump(contents))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WwgRs06k1Z0v"
      },
      "source": [
        "### Make metadata.csv corpus\n",
        "Saved to output_path/raw_data/speaker_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT9s7mZH1OMa",
        "outputId": "8ee1e2ba-ac3d-42d1-c375-0402b5b56f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset path: /gdrive/MyDrive/MyDataset\n",
            "Corpus path: /content/output_dataset/raw_data/universal/metadata.csv\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Don't overwrite existing file\n",
        "if not allow_overwrite_existing_corpus:\n",
        "  assert(not os.path.exists(corpus_file_path)), 'Corpus file already exists, enable `allow_overwrite_existing_corpus` to disable this behavior.'\n",
        "\n",
        "\n",
        "def concatenate_file_contents(filename):\n",
        "    \"\"\" Reads text file and outputs string with name of file and contents \"\"\"\n",
        "    filename_no_ext = str(os.path.basename(filename)).replace(text_file_extension,'')\n",
        "    with open(filename, 'r') as file:\n",
        "      contents = file.read().strip()\n",
        "      result = f\"{filename_no_ext}|{contents}|{contents}\\r\\n\"\n",
        "      return result\n",
        "\n",
        "\n",
        "def process_files_in_path(text_files_path, output_corpus_file_path):\n",
        "    \"\"\" Open a file at output_corpus_path and write formatted data to it \"\"\"\n",
        "    with open(output_corpus_file_path, 'w') as f:\n",
        "        # Get all .txt files in the specified path\n",
        "        txt_files = [file for file in os.listdir(text_files_path) if file.endswith(text_file_extension)]\n",
        "        txt_files_count = len(txt_files)\n",
        "        if txt_files_count <= 0:\n",
        "          print(f'No text files with extension {text_file_extension} found in {text_files_path}, try changing `text_file_extension` in settings')\n",
        "        # Process each file and concatenate the contents\n",
        "        for file in txt_files:\n",
        "          file_path = os.path.join(text_files_path, file)\n",
        "          output = concatenate_file_contents(file_path)\n",
        "          f.write(output)\n",
        "# Run\n",
        "print(f'Dataset path: {dataset_path}')\n",
        "print(f'Corpus path: {corpus_file_path}')\n",
        "process_files_in_path(dataset_path, corpus_file_path)\n",
        "print('Done')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dG88YPpkWe2B"
      },
      "source": [
        "### Create configuration files\n",
        "Modify LJSpeech config with user defined parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMx1ij0HWbLv",
        "outputId": "ddaed4bc-1cf0-4ba3-f0ac-be66345d610d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò/content/output_dataset/configs‚Äô: File exists\n",
            "Wrote configs in /content/FastSpeech2/config/MyDataset, copying to /content/output_dataset/configs\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "try:\n",
        "    from yaml import CLoader as Loader, CDumper as Dumper\n",
        "except ImportError:\n",
        "    from yaml import Loader, Dumper\n",
        "\n",
        "copied_config_dir = os.path.join(output_path, 'configs')\n",
        "\n",
        "!mkdir -p $config_dir \n",
        "!mkdir $copied_config_dir\n",
        "!cp -r /content/FastSpeech2/config/LJSpeech/* $config_dir\n",
        "\n",
        "# model.yaml - change speaker name\n",
        "model = get_yaml_contents('model')\n",
        "model['vocoder']['speaker'] = speaker_name\n",
        "write_yaml('model', model)\n",
        "\n",
        "# preprocess.yaml - update paths and add field to text\n",
        "pp = get_yaml_contents('preprocess')\n",
        "pp['dataset'] = dataset_name\n",
        "pp['path']['corpus_path'] = corpus_path\n",
        "pp['path']['lexicon_path'] = lexicon_path\n",
        "pp['path']['raw_path'] = raw_data_path\n",
        "pp['path']['preprocessed_path'] = preprocessed_data_speaker_path\n",
        "pp['preprocessing']['text']['max_length'] = 4096  # Needed for training EfficientSpeech models\n",
        "pp['preprocessing']['val_size'] = val_size  # Needed for training EfficientSpeech models\n",
        "\n",
        "write_yaml('preprocess', pp)\n",
        "\n",
        "# train.yaml - update paths\n",
        "tr = get_yaml_contents('train')\n",
        "tr['path']['ckpt_path'] = f'./output/ckpt/{dataset_name}'\n",
        "tr['path']['log_path'] = f'./output/log/{dataset_name}'\n",
        "tr['path']['result_path'] = f'./output/result/{dataset_name}'\n",
        "write_yaml('train', tr)\n",
        "\n",
        "print(f'Wrote configs in {config_dir}, copying to {copied_config_dir}')\n",
        "!cp -r $config_dir $copied_config_dir\n",
        "print('Done')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xIxc6NUtfuKX"
      },
      "source": [
        "### Prepare align\n",
        "The following code is modified from https://github.com/ming024/FastSpeech2/blob/master/preprocessor/ljspeech.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PXl_dbkf6xk",
        "outputId": "c69bf03b-ed0d-416f-9b6f-3ccf20c04830"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [00:05,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepare align done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#The following code is modified from \n",
        "# https://github.com/ming024/FastSpeech2/blob/master/preprocessor/ljspeech.py\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "try:\n",
        "    from yaml import CLoader as Loader, CDumper as Dumper\n",
        "except ImportError:\n",
        "    from yaml import Loader, Dumper\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Workaround for importing text\n",
        "import sys\n",
        "sys.path.append('/content/FastSpeech2')\n",
        "from text import _clean_text\n",
        "\n",
        "\n",
        "def prepare_align(config):\n",
        "    sampling_rate = config[\"preprocessing\"][\"audio\"][\"sampling_rate\"]\n",
        "    max_wav_value = config[\"preprocessing\"][\"audio\"][\"max_wav_value\"]\n",
        "    cleaners = config[\"preprocessing\"][\"text\"][\"text_cleaners\"]\n",
        "    speaker = speaker_name\n",
        "    with open(corpus_file_path, encoding=\"utf-8\") as f:\n",
        "        for line in tqdm(f):\n",
        "            parts = line.strip().split(\"|\")\n",
        "            base_name = parts[0]\n",
        "            text = parts[2]\n",
        "            text = _clean_text(text, cleaners)\n",
        "\n",
        "            wav_path = os.path.join(dataset_path, \"{}.wav\".format(base_name))\n",
        "            if os.path.exists(wav_path):\n",
        "                os.makedirs(raw_data_speaker_path, exist_ok=True)\n",
        "                wav, sr = librosa.load(wav_path, sr=sampling_rate)\n",
        "                #wav, _ = librosa.load(wav_path, sampling_rate)\n",
        "                wav = wav / max(abs(wav)) * max_wav_value\n",
        "                wavfile.write(\n",
        "                    os.path.join(raw_data_speaker_path, \"{}.wav\".format(base_name)),\n",
        "                    sampling_rate,\n",
        "                    wav.astype(np.int16),\n",
        "                )\n",
        "                with open(\n",
        "                    os.path.join(raw_data_speaker_path, \"{}.lab\".format(base_name)),\n",
        "                    \"w\",\n",
        "                ) as f1:\n",
        "                    f1.write(text)\n",
        "\n",
        "\n",
        "config = get_yaml_contents('preprocess')\n",
        "prepare_align(config)\n",
        "print('Prepare align done')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kHqaO0dcCofH"
      },
      "source": [
        "### Run MFA forced alignment\n",
        "Creates TextGrid files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrR33GuhDArV",
        "outputId": "4474a70a-5506-45c6-f32d-31213037dec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running mfa align with arguments: --clean --single_speaker /content/output_dataset/raw_data/universal /content/FastSpeech2/lexicon/librispeech-lexicon.txt english_us_arpa /home/mfa_user/MyDataset/TextGrid\n",
            "The global MFA database server does not exist, initializing it first.\n",
            "waiting for server to start.... done\n",
            "server started\n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Setting up corpus information\u001b[33m...\u001b[0m                                      \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Loading corpus from source files\u001b[33m...\u001b[0m                                   \n",
            "\u001b[2K\u001b[35m   0%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/100 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Found \u001b[1;36m1\u001b[0m speaker across \u001b[1;36m9\u001b[0m files, average number of utterances per      \n",
            "\u001b[2;36m \u001b[0m         speaker: \u001b[1;36m9.0\u001b[0m                                                          \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initializing multiprocessing jobs\u001b[33m...\u001b[0m                                  \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Normalizing text\u001b[33m...\u001b[0m                                                   \n",
            "\u001b[2K\u001b[35m  78%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/9 \u001b[0m [ \u001b[33m0:00:05\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m31 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Creating corpus split for feature generation\u001b[33m...\u001b[0m                       \n",
            "\u001b[2K\u001b[35m   6%\u001b[0m \u001b[91m‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/18 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating MFCCs\u001b[33m...\u001b[0m                                                   \n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9/9 \u001b[0m [ \u001b[33m0:00:05\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m3 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Calculating CMVN\u001b[33m...\u001b[0m                                                   \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating final features\u001b[33m...\u001b[0m                                          \n",
            "\u001b[2K\u001b[35m  11%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/9 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Creating corpus split with features\u001b[33m...\u001b[0m                                \n",
            "\u001b[2K\u001b[35m  11%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/9 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Compiling training graphs\u001b[33m...\u001b[0m                                          \n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9/9 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m49 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Performing first-pass alignment\u001b[33m...\u001b[0m                                    \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating alignments\u001b[33m...\u001b[0m                                              \n",
            "\u001b[2K\u001b[35m  44%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/9 \u001b[0m [ \u001b[33m0:00:02\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m13 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Calculating fMLLR for speaker adaptation\u001b[33m...\u001b[0m                           \n",
            "\u001b[2K\u001b[35m 100%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Performing second-pass alignment\u001b[33m...\u001b[0m                                   \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Generating alignments\u001b[33m...\u001b[0m                                              \n",
            "\u001b[2K\u001b[35m  78%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/9 \u001b[0m [ \u001b[33m0:00:02\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m32 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Collecting phone and word alignments from alignment lattices\u001b[33m...\u001b[0m       \n",
            "\u001b[2K\u001b[35m  78%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/9 \u001b[0m [ \u001b[33m0:00:09\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m17 it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Alignment analysis not available without using postgresql             \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Exporting alignment TextGrids to \u001b[35m/home/mfa_user/MyDataset/\u001b[0m\u001b[95mTextGrid...\u001b[0m \n",
            "\u001b[2K\u001b[35m  11%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/9 \u001b[0m [ \u001b[33m0:00:02\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25h\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Finished exporting TextGrids to \u001b[35m/home/mfa_user/MyDataset/\u001b[0m\u001b[95mTextGrid\u001b[0m!    \n",
            "\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Done! Everything took \u001b[1;36m74.541\u001b[0m seconds                                  \n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Output TextGrid files go here\n",
        "!su - mfa_user -c \"mkdir -p $mfa_output_path\"\n",
        "%mkdir -p $textgrid_dir\n",
        "\n",
        "# Allow mfa_user access to output directory \n",
        "!chown mfa_user $textgrid_dir\n",
        "\n",
        "# Command line options\n",
        "# -m fast: immediate disconnect (doesn't work sadface)\n",
        "# --clean: cleans output dir for subsequent runs (if off, \n",
        "#             does not overwrite old data)\n",
        "# --single_speaker: multiprocessing for only one speaker\n",
        "mfa_cmd_opts = f'--clean --single_speaker'\n",
        "align_cmd_opts = f'{corpus_path} {dictionary_file} {acoustic_model} {mfa_output_path}'\n",
        "\n",
        "# Command must be run as unprivileged user\n",
        "!echo Running mfa align with arguments: $mfa_cmd_opts $align_cmd_opts\n",
        "!su - mfa_user -c \"mfa align $mfa_cmd_opts $align_cmd_opts\"\n",
        "\n",
        "# If the cell hangs you can terminate it early after it says \"Exporting alignment TextGrids to...\"\n",
        "#!echo Copying TextGrid files to $textgrid_dir\n",
        "#!cp $mfa_output_path/*.* $textgrid_dir "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3c3tzL3bV78T"
      },
      "source": [
        "Copy output of above to dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b36FmXzEV6Yu",
        "outputId": "1e6c082a-4f3e-4ac1-8c6b-b45f74322000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying TextGrid files to /content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal\n"
          ]
        }
      ],
      "source": [
        "!echo Copying TextGrid files to $textgrid_dir\n",
        "!cp $mfa_output_path/*.* $textgrid_dir "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sWT4zYzl47Vr"
      },
      "source": [
        "## Preprocess TextGrid files for preprocessed_data/ folder\n",
        "This creates the files in preprocessed_data/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEjO6Np05TFh",
        "outputId": "967ceb04-16ee-4fe9-bbf2-332cb3b5794d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/FastSpeech2/audio/stft.py:42: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  fft_window = pad_center(fft_window, filter_length)\n",
            "/content/FastSpeech2/audio/stft.py:145: FutureWarning: Pass sr=22050, n_fft=1024, n_mels=80, fmin=0, fmax=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  mel_basis = librosa_mel_fn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Data ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing statistic quantities ...\n",
            "Total time: 0.01080050390526581 hours\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['p303_009|universal|{DH EH1 R IH0 Z AH0 K AO1 R D IH0 NG T IH0 L EH1 JH AH0 N D AH0 B OY1 L IH0 NG P AA1 T AH0 V G OW1 L D AE1 T W AH1 N EH1 N D}|there is , according to legend, a boiling pot of gold at one end.',\n",
              " 'p303_003|universal|{S IH1 K S S P UW1 N Z AH0 V F R EH1 SH S N OW1 P IY1 Z F AY1 V TH IH1 K S L AE1 B Z AH0 V B L UW1 CH IY1 Z AE1 N D M EY1 B IY0 EY1 S N AE1 K F R ER0 HH ER0 B R AH1 DH ER0 B AA1 B}|six spoons of fresh snow peas, five thick slabs of blue cheese, and maybe a snack for her brother bob.',\n",
              " 'p303_002|universal|{AE1 S K HH ER1 T UW1 B R IH1 NG DH IY1 Z TH IH1 NG Z W IH1 TH HH ER0 F R AH1 M DH AH0 S T AO1 R}|ask her to bring these things with her from the store.',\n",
              " 'p303_005|universal|{SH IY1 K AH0 N S K UW1 P DH IY1 Z TH IH1 NG Z IH0 N T AH0 TH R IY1 R EH1 D B AE1 G Z AE1 N D W IY1 W AH0 L G OW1 M IY1 T HH ER1 W EH1 N Z D EY2 AE1 T DH AH0 T R EY1 N S T EY1 SH AH0 N}|she can scoop these things into three red bags, and we will go meet her wednesday at the train station.',\n",
              " 'p303_001|universal|{P L IY1 Z K AO1 L S T EH1 L AH0}|please call stella.',\n",
              " 'p303_008|universal|{DH IY1 Z T EY1 K DH IY0 SH EY1 P AH0 V AH0 L AO1 NG R AW1 N D AA1 R CH W IH0 TH IH1 T S P AE1 TH HH AY1 AH0 B AH1 V AE1 N D IH1 T S T UW1 EH1 N D Z AH0 P EH1 R AH0 N T L IY0 B IY2 AO1 N D DH AH0 HH ER0 AY1 Z AH0 N}|these take the shape of a long round arch, with its path high above, and its two ends apparently beyond the horizon.',\n",
              " 'p303_006|universal|{HH W IH1 N DH AH0 S AH1 N L AY2 T S T R AY1 K S R EY1 N D R AA2 P S IH1 N DH IY0 EH1 R DH EY1 AE1 K T EH1 Z AH0 P R IH1 Z AH0 M AE1 N D F AO1 R M AH0 R EY1 N B OW2}|when the sunlight strikes raindrops in the air, they act as a prism and form a rainbow.',\n",
              " 'p303_004|universal|{W IY1 AO1 L S OW0 N IY1 D AH0 S M AO1 L P L AE1 S T IH0 K S N EY1 K AE1 N D AH0 B IH1 G T OY1 F R AA1 G F ER0 DH IY0 K IH1 D Z}|we also need a small plastic snake and a big toy frog for the kids.',\n",
              " 'p303_007|universal|{DH AH0 R EY1 N B OW2 IH0 Z AH0 D IH0 V IH1 ZH AH0 N AH0 V W AY1 T L AY1 T IH0 N T AH0 M EH1 N IY0 B Y UW1 T AH0 F AH0 L K AH1 L ER0 Z}|the rainbow is a division of white light into many beautiful colors.']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/FastSpeech2')\n",
        "from preprocessor.preprocessor import Preprocessor\n",
        "\n",
        "config = get_yaml_contents('preprocess')\n",
        "preprocessor = Preprocessor(config)\n",
        "preprocessor.build_from_path()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ISDI0-_jfIkX"
      },
      "source": [
        "## Save out processed dataset\n",
        "Saves to your Drive by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awXbGQeFfTRM",
        "outputId": "d5bae30d-6e67-4d18-cd8a-8b1f967bb837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Saving dataset as MyDataset.zip at /gdrive/MyDrive/output_dataset\n",
            "updating: content/output_dataset/ (stored 0%)\n",
            "  adding: content/output_dataset/raw_data/ (stored 0%)\n",
            "  adding: content/output_dataset/raw_data/universal/ (stored 0%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_008.wav (deflated 16%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_004.lab (deflated 9%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_003.wav (deflated 14%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_005.wav (deflated 14%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_005.lab (deflated 22%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_001.wav (deflated 19%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_003.lab (deflated 22%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_004.wav (deflated 17%)\n",
            "  adding: content/output_dataset/raw_data/universal/metadata.csv (deflated 68%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_007.wav (deflated 15%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_007.lab (deflated 12%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_009.lab (deflated 9%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_009.wav (deflated 17%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_008.lab (deflated 23%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_006.wav (deflated 17%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_006.lab (deflated 18%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_002.wav (deflated 18%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_002.lab (deflated 11%)\n",
            "  adding: content/output_dataset/raw_data/universal/p303_001.lab (stored 0%)\n",
            "  adding: content/output_dataset/configs/ (stored 0%)\n",
            "  adding: content/output_dataset/configs/MyDataset/ (stored 0%)\n",
            "  adding: content/output_dataset/configs/MyDataset/model.yaml (deflated 50%)\n",
            "  adding: content/output_dataset/configs/MyDataset/train.yaml (deflated 51%)\n",
            "  adding: content/output_dataset/configs/MyDataset/preprocess.yaml (deflated 54%)\n",
            "  adding: content/output_dataset/preprocessed_data/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_005.npy (deflated 12%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_003.npy (deflated 13%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_007.npy (deflated 12%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_001.npy (deflated 13%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_006.npy (deflated 13%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_002.npy (deflated 12%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_004.npy (deflated 13%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_009.npy (deflated 12%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/mel/universal-mel-p303_008.npy (deflated 12%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/train.txt (deflated 48%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_009.npy (deflated 16%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_003.npy (deflated 11%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_004.npy (deflated 15%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_001.npy (deflated 32%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_007.npy (deflated 15%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_002.npy (deflated 20%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_005.npy (deflated 11%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_006.npy (deflated 13%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/energy/universal-energy-p303_008.npy (deflated 10%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_005.TextGrid (deflated 88%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_001.TextGrid (deflated 82%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_008.TextGrid (deflated 88%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_002.TextGrid (deflated 86%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_003.TextGrid (deflated 88%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_007.TextGrid (deflated 87%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_004.TextGrid (deflated 87%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_006.TextGrid (deflated 87%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/TextGrid/universal/p303_009.TextGrid (deflated 87%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/stats.json (deflated 28%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_004.npy (deflated 7%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_008.npy (deflated 4%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_002.npy (deflated 15%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_007.npy (deflated 7%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_006.npy (deflated 4%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_003.npy (deflated 5%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_001.npy (deflated 24%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_009.npy (deflated 7%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/pitch/universal-pitch-p303_005.npy (deflated 4%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/val.txt (deflated 47%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/ (stored 0%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_008.npy (deflated 74%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_004.npy (deflated 71%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_007.npy (deflated 71%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_006.npy (deflated 73%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_005.npy (deflated 73%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_003.npy (deflated 73%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_009.npy (deflated 70%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_002.npy (deflated 68%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/duration/universal-duration-p303_001.npy (deflated 60%)\n",
            "  adding: content/output_dataset/preprocessed_data/MyDataset/speakers.json (stored 0%)\n",
            "Done, copied to /gdrive/MyDrive/output_dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "\n",
        "zip_name = f'{dataset_name}.zip'\n",
        "\n",
        "!echo Saving dataset as $zip_name at $output_zip_path\n",
        "!zip -r $zip_name $output_path\n",
        "!cp $zip_name $output_zip_path\n",
        "!echo Done, copied to $output_zip_path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uX01HIvSEZ-M"
      },
      "source": [
        "\n",
        "\n",
        "#  \n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
